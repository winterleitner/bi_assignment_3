---
output:
  bookdown::pdf_book:
    template: sample-sigchi.tex
    keep_tex: true
    citation_package: natbib
    fig_caption: true
title: Predicting the resale value of used cars
abstract: This is Assignment 3 in Business Intelligence @ TU Wien in the winter term of 2020.
bibliography: my-bibliography.bib

---

```{r setup, include=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(GGally)
library(ggcorrplot)

audi <- read_csv("data/audi.csv")
audi['brand'] = "Audi"

bmw <- read_csv("data/bmw.csv")
bmw['brand'] = "BMW"

ford <- read_csv("data/ford.csv")
ford['brand'] = "Ford"

hyundi <- read_csv("data/hyundi.csv")
hyundi['brand'] = "Hyundai"

merc <- read_csv("data/merc.csv")
merc['brand'] = "Mercedes"

skoda <- read_csv("data/skoda.csv")
skoda['brand'] = "Skoda"

toyota <- read_csv("data/toyota.csv")
toyota['brand'] = "Toyota"

vauxhall <- read_csv("data/vauxhall.csv")
vauxhall['brand'] = "Vauxhall"

vw <- read_csv("data/vw.csv")
vw['brand'] = "VW"

car_data <- rbind(audi, bmw, ford, hyundi, merc, skoda, toyota, vauxhall, vw)
car_data <- car_data %>%
  select('brand', everything())
car_data <- car_data %>% relocate('price', .after = last_col())

#replace year with age
car_data$age = 2020 - car_data$year
```

# Introduction
For this project, we used a dataset found on Kaggle.com provided by user Aditya [@Aditya]. It contains a collection of different used car listings obtained by searching through online marketplaces using a web scraper. The dataset is split into different files, one per car brand. The brands for which data is available are:

* Audi
* BMW
* Ford
* Hyundai
* Mercedes
* Skoda
* Toyota
* Vauxhall (= Opel in Great Britain)
* VW

Additionally, the data set contains files with premade subsets of above mentioned car brands, for example *cclass.csv*, which contains only listings for the Mercedes model C Class. We chose to only utilize the unfiltered datasets.

Apart from the car brand, there are a number of other attributes available for each data entry.

* car model
* year of first registration
* transmission type
* mileage
* fuel type
* tax
* miles per gallon of fuel
* engine size

as well as the target variable price.

# Business Understanding

## a. Scenario

A group of entrepreneurs in the used car business want to counteract the ongoing trend of people selling their cars to other private individuals directly without involving commercial reseller, which has become very easy given the availability of online market places for used goods. The idea is the following: Customers are offered a new web-based platform where they can enter the most important key facts about the car they would like to sell. The platform immediately returns a first estimate of the price the platform owners would pay for the car. This estimate should be based on a model created from the used car listing data available.

## b. Business Objectives

The business objectives is in short:

**What is the expected value of a used car based on the given data entries?**

Answering this question helps the platform in multiple ways.

* make it more convenient for customers to sell their used car by getting an accurate first estimate right after entering the data
* increase revenues by missing out on fewer chances to buy used cars (more cars resold via the platform instead of directly to other buyers)
* speed up final evaluation of car value by offering a good starting point
* base offers made to customers on true market values

## c. Business Success Criteria

The following criteria need to be met by the prediction:

* The estimate should lead to a conversion rate of more than 30%, meaning that at least 30% of the users that enter their car data on the website actually proceed to sell their car on the platform.

* The estimations should never lead to an effective loss for the company. Therefore, estimations that are too high need to be avoided.


## d. Data Mining Goals

In order to fulfill the business objective of determining an accurate price estimate, a regression problem needs to be solved. The input data consists of the 9 attributes mentioned above.

## e. Data Mining Success Criteria

Regarding the result of the estimation, one important success criterion is:

* The estimate needs to be within a range of the actual price +/- 15% for 95% of the estimations made.

This is important because estimates that are further off the actual price may lead to:

* People aborting the process when the estimate is much lower than their expectation
* People entering the negotiations with far inflated expectation, effectively reducing the changes of the platform owners to score a good deal


# Data Understanding
In the following section, a data description report containing data types, statistical properties, data quality aspects as well as a visual exploration of data properties is presented.

## a. Data Types
The attributes in the data set have the data types shown in **Table \@ref(tab:table-datatypes).**

```{r echo=FALSE}
Attribute <- c("model", "age", "year", "transmission", "mileage", "fuelType", "tax", "mpg", "engineSize", "price");
Type <- c("String, nominal", "Integer, interval", "Integer, ratio", "String, nominal", "Integer, ratio", "String, nominal", "Integer, ratio", "Float, ratio", "Float, ratio", "Integer, ratio")
data_types <- data.frame(Attribute, Type)
```

```{r table-datatypes, echo=FALSE}
data_types %>%
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Data Types of the source data")
```


## b. Statistical Properties

```{r}
options(width = 60)
summary(car_data)
```


## c. Data Quality aspects
Since the data is recorded from the internet there is the possibility of it containing invalid information or missing values.

To begin with, we check the data for missing values. However, in this speficic case, there are none.
```{r}
dim(car_data) ==
  dim(car_data[complete.cases(car_data),])
```

Next up, we check plausibility of some of the extreme cases of numerical values. To keep it short, we only included one exemplary output her and then summarize the findings.
```{r}
options(width = 60)
head(car_data[order(car_data$age),], 5)
# year 2060 is an error

head(car_data[order(-car_data$age),], 5)
# the oldest cars seem realistic
```
```{r echo=FALSE, include=FALSE}
#MILEAGE
head(car_data[order(car_data$mileage),], 10)
# year 2008 and only one mile does not seem realistic, especially given the price.

head(car_data[order(-car_data$mileage),], 10)
# other end looks good

# TAX
head(car_data[order(car_data$tax),], 10)
# tax seems realistic on the low end ("slow" cars = low tax)

head(car_data[order(-car_data$tax),], 10)
# tax seems realistic on the top end (fast cars = high tax)

# MPG
head(car_data[order(car_data$mpg),], 10)
head(car_data[order(-car_data$mpg),], 10)
# for MPG, both high and low and values do not seem realistic. There is definitely some need for cleaning here.

# ENGINE SIZE
head(car_data[order(car_data$engineSize),], 10)
head(car_data[order(-car_data$engineSize),], 10)
# on the upper end, everything looks good, but there are entries with engine size = 0 for petrol and diesel cars, which is not possible

# Price
head(car_data[order(car_data$price),], 10)
head(car_data[order(-car_data$price),], 10)
# pricing for the extreme values looks pretty good, however in the top 10, we were wondering if the high prices for e.g. the Mercedes A-Class (>130.000) are authentic.
```
Most of the extreme values in the dataset were realistic. Some entries contain questionable combinations of age and mileage, unrealistically high or low MPG values or "0" engine sizes. In those cases, some filtering should be done.

## d. Visual Exploration of data properties and hypotheses

In the following figures, boxplots illustrate the ranges of the numeric (ratio) variables.

```{r figure-boxplots, echo=FALSE, out.width='0.98\\textwidth', fig.env='figure*', fig.cap="Boxplots on the distribution of the numeric attributes"}
par(mfcol = c(1, 5), mai=c(0.3,0.3,0.3,0.1), cex = 0.7)
boxplot(car_data$engineSize, main="Engine Size")
boxplot(car_data$mileage, main="Mileage")
boxplot(car_data$price, main="Price")
boxplot(car_data$mpg, main="MPG")
boxplot(car_data$tax, main="Tax")
par(mfcol = c(1, 1))
```
There are a few things we can learn from these diagrams. For example, it is interesting to see car listings contained in the data set are mostly for rather new cars, with a mileage median of less than 25000 miles. Taking a look at **Figure \@ref(fig:car-age)**, this suspicion is confirmed. The vast majority of cars in the dataset is indeed less than five years old. There is `r length(car_data$age[car_data$age < 0])` entry where the cars year is seemingly bigger than 2020, that is 2060, which will have to be dealt with in later steps.

```{r car-age, echo=FALSE, out.width='0.98\\columnwidth', fig.cap="Histogram of car age."}
hist(car_data$age[car_data$age >= 0], xlim= c(0,30), main="Histogram of car age", xlab="Age (cleaned age < 0 entries)")
```

The correlation plot in **Figure \@ref(fig:correlationmatrix)** shows some pretty good correlation between ther predictor variables and the price, so we might be able to create a solid regression using the data available.

```{r, correlationmatrix, echo=FALSE, out.width='0.98\\columnwidth', fig.cap="Pairs of all numeric attributes"}
ggcorrplot(cor(data.matrix(car_data)))
```
From the view point of a human estimating the value of a used car, the most influential attributes should be age, mileage and brand/model as well as general condition, which is however not part of our dataset. Looking at the correlation matrix, we see that there is indeed a significant correlation between price and age as well as mileage. For model and brand, the correlation is much lower.

# Data Preparation report

## a. Potential for derived attributes

One adjustment that was already made right after importing the data was deriving the variable **age** from **year**. Our thoughts behind this decision were that as time progresses, a car's value usually decreases. Therefore, if we only use the year, we would have to discard all existing data sooner or later because it would be outdated. The age of the car at the time of the listing is a much more stable attribute in that regard. One assumption that we had to make here is that all the listings were collected in 2020, otherwise our age assignment would be wrong.
Other than that, we could not think of any variables where it would have made sense to derive new attributes.

## b. Potential for additional data sources

An attribute that we were especially missing in the dataset was **horse power**. Whilst we have different engine sizes in terms of stroke volume included, in practice we often see engines with the same size produce different amounts of maximal performance. Pricing is of course also higher for stronger engines (within a car model's options). Therefore, having additional horse power data in the set would have been desirable. Unfortunately, in many cases, it is impossible to add that information at a later point in time, since there is no reference to the original car listing included. In some cases, deriving the horse power from the other attributes might be possible. Usually, there will, however, be multiple choices, making it impossible to assign a value with 100% certainty.

Another very important aspect is the **condition** of the car. As previously mentioned, without knowing about the amount of damage that has already been done to a car, it is virtually impossible to judge its value. **Color** would be another interesting aspect since black or white cars are easier to sell than pink ones and therefore worth more. For both of these aspects, it is unfortunately again impossible to obtain values for the existing data set.

## Other Pre-Processing steps

In the following section, we will prepare the dataset for modeling but applying the needed corrections identified before.

#### Removing Outliers

In 2c) we identified several entries that cannot be valid data. Next, we remove those entries from our data frame.

First, there is one entry with a negative age.

```{r}
car_data <- car_data[car_data$age >= 0, ]
```

Next, we filter a few rows that seem unrealistic in terms of mileage and age.

```{r}
car_data <- car_data[!(car_data$mileage < 1000 & car_data$age > 5), ]
```

The filtering becomes a little more interesting for miles per gallon. A quick Internet research produced the following results. In 2020, new cars with a combustion engine should be able to achieve around 25 miles per gallon on average. Top performers among hybrid cars can manage up to around 60 miles per hour. Everything significantly higher than that is currently not possible. On the lower end, we looked up some high performance sports cars. Even for the most powerful cars like the Bugatti Chiron or the Lamborghini Aventador, fuel economy scores were around 10 miles per gallon.

```{r}
nrow(car_data[car_data$mpg > 60, ])
```
Unfortunately, the car listings in the dataset do not seem to agree with this information. Around one third of the car listings show MPG values higher than 60. Upon further inspection, we came to the conclusion that the MPG values from the listings might correspond to manufacturer ideal values that are practically unobtainable in real world use. For petrol cars, the the mean of the MPG values is about 50, which is way higher than expected.

```{r}
summary(car_data[car_data$fuelType == "Petrol", ]$mpg)
```

For hybrid cars, the quartiles were higher, as expected.
```{r}
summary(car_data[car_data$fuelType == "Hybrid", ]$mpg)
```

Our strategy to clean the data here therefore was to not remove overall outliers, but outliers per fuel type.

```{r, echo=FALSE, include=FALSE}
old_length <- length(car_data)
```


```{r}
types <- distinct(car_data, car_data$fuelType)[, 1]$`car_data$fuelType`
for (type in types) {
  outliers <- boxplot(car_data[car_data$fuelType == type, ]$mpg, plot=FALSE)$out
  if (length(outliers) > 0) {
    car_data <- car_data[-which(car_data$mpg %in% outliers & car_data$fuelType == type),]
  }
}
```
This outlier removal procedure effectively filtered out `r old_length - length(car_data)` entries from the data frame.


c. Describe other pre-processing steps considered, specifying which ones were applied or not applied due to which reason. (e.g. data cleansing, transformations, binning, scaling, outlier removal, attribute removal, transcoding, ...) at a level of detail that ensures reproducibility of changes to the data. (Code may be supplied as supplement to the submission in case you produce your own code)


# Modeling
Insert content here.
```{r, echo=FALSE, include=FALSE}
trainsample <- sample(seq_len(nrow(car_data)),size = floor(0.75 * nrow(car_data)))

formula <- price~brand+mpg+mileage+year+transmission+fuelType+tax+engineSize
formula2 <- price~brand+mpg+mileage+year+transmission+fuelType+tax+engineSize+model

# encountered issue -> depending on the training and testing set it can be that one model is newly introduced in the testset which is not presen in the training set.
# This could also happen in the daily use of the system when new carmodels are introduces. How can this be handeld?
# Looking at the correlation matrix, the model of a car does not have high correlation with the price

# Analysing data on the carmodels
barplot(prop.table(table(car_data$model)))
head(sort(table(car_data$model),decreasing = TRUE),5)
tail(sort(table(car_data$model),decreasing = TRUE),5)
# reveals that some carmodels are only present once in the datamodel

# Carmodels missing in the trainingdata
missing_fact <- setdiff(unique(car_data[-trainsample,]$model), unique(car_data[trainsample,]$model))
testing_data <- car_data[-trainsample,]
cleaned_testing_data <- testing_data[!testing_data$model %in% missing_fact,]

# glm
glm_model <- lm(formula2,data = car_data[trainsample,])
glm_pred <- predict(glm_model,cleaned_testing_data)

# decision tree

# library(rpart)
# tree_model <- rpart(formula2,method = "anova", data = car_data[trainsample,])
# tree_pred <- predict(tree_model, cleaned_testing_data)

library(mgcv)
# Build the model
gam_model <- gam(price~ brand+s(mpg)+s(mileage)+s(year)+transmission+fuelType+tax+s(engineSize)+model, data = car_data[trainsample,])
# Make predictions
gam_pred <- gam_model %>% predict(cleaned_testing_data)



```

a. Identify suitable data mining algorithms and select one of these as the most suitable for your experiments, providing a brief justification.

The goal is to estimate the price for a car based on it inputed characteristics based on the training data containing nine attributes as well as the prediction lable. Therefore it is a supervised learning with regression, prediction of a numerical value.

When choosing the a regression model it has to deliver sufficient results, while being efficient in computation.
While complex regression models might deliver higher accuracies, they easily become difficult to interpret and follow back decisions.
Generalized linear regression is the got to regression model as it is fast to train and delivers good estimates and predictions. It's computational requirements depending on the data are managable.

b. Identify the hyper-parameters available for tuning in your chosen algorithm and select one that you deem most relevant for tuning, providing a brief justification.

Choosing a linear regression model leaves open the possibility to modify the formula to reproduce a linear relationship between the attributes and the predicted value. While doing it manually is very timeintensive and inefficient it can be implemented with the use of Generalized additive models (gam). This model allows to apply smoothing functions on the single parameters to improve prediction outcome. Effectively combining generalized linear models with additive models.


c. Define and document a train / validation / test set split, considering where necessary appropriate stratification, any dependencies between data instances (e.g. time series data) and relative sizes of the respective subsets.

While dividing the data in train and test, some scarse carmodel, meaning of low quantities up to being unique, 

d. Train the model on the training set and comparing the performance on the validation set to identify the best hyper-parameter setting, explicitly documenting all parameter settings (avoid stating simply to have used “default parameters”, focus on reproducibility of the results you report).

e. Report suitable performance metrics supported, where possible, by figures/graphs showing the tuning process of the hyper parameter.

```{r}
# summary
summary(glm_model)$r.squared
summary(gam_model)$r.sq
```

# Evaluation
Insert content here.

a. Apply the final model on the test data and document performance.

```{r}
# Evaluate models
plot(cleaned_testing_data$price,glm_pred)
plot(cleaned_testing_data$price,gam_pred)

hist(cleaned_testing_data$price-glm_pred,breaks = 200)
hist(cleaned_testing_data$price-gam_pred,breaks = 200)

mean(abs((cleaned_testing_data$price - glm_pred)/cleaned_testing_data$price))
boxplot(cleaned_testing_data$price - glm_pred)

# mean(abs(cleaned_testing_data$price - tree_pred))
# hist(abs(cleaned_testing_data$price - tree_pred),200)

mean(abs((cleaned_testing_data$price - gam_pred)/cleaned_testing_data$price))
boxplot(cleaned_testing_data$price - gam_pred)

summary(abs((cleaned_testing_data$price - gam_pred)/cleaned_testing_data$price))
```

b. Re-train the model with identical hyper-parameters using the full train and validation data and again apply it on the test data, documenting the performance
c. Identify and document
    i. state-of-the-art performance from the literature using the same (albeit potentially slightly differently pre-processed) data set from the literature.
    ii. the expected base-line performance of a trivial acceptor / rejecter or random classifier
d. Compare the performance achieved with the benchmark and baseline performances (c.f. Section 1e – Data Mining success Criteria) according to different metrics (i.e. overall, but also on per-class level (confusion matrix), micro/macro precision/recall in the case of classification tasks, regression errors in certain parts of the data space, ... (Note your goal is not necessarily to obtain a better result than what has been reported in the state of the art, this is not a grading criterion! On the other hand, if the performance of your classifiers is massively below the stat of the art (or even below a random baseline or trivial acceptor / rejecter) you may want to investigate the reason...)
e. Compare the performance obtained with the Data Mining success criteria defined in the business understanding phase.


# Deployment
Insert content here.

a. Compare the performance obtained with respect to the needs for addressing the business success criteria and provide recommendations for deployment (fully automatic, hybrid solutions, deploying only for a part of the data space, ...) as well as recommendations for subsequent analysis.
b. Consider and briefly document potential ethical aspects as well as impact assessment / risks identified in deployment
c. Document aspects to be monitored during deployment, specifying triggers that should lead to intervention.
d. Briefly re-visit reproducibility aspects reflecting on aspects well documented and those that might pose a risk in terms of reproducibility based solely on the information provided in this report


# Summary of findings
Insert content here.


a. Briefly summarize your overall findings and lessons learned
b. (optional) Provide feedback on this exercise in general: which parts were useful / less useful; which other kind of experiment would have been interesting, ... (this section is, obviously, optional and will not be considered for grading. You may also decide to provide that kind of feedback anonymously via the feedback mechanism in TISS – in any case we would appreciate learning about it to adjust the exercises for next year following a major re-structuring this year based on feedback obtained.)
