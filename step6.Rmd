---
output:
  bookdown::pdf_book:
    template: sample-sigchi.tex
    keep_tex: true
    citation_package: natbib
    fig_caption: true
title: Predicting the resale value of used cars
abstract: This is Assignment 3 in Business Intelligence @ TU Wien in the winter term of 2020.
bibliography: my-bibliography.bib

---

```{r setup, include=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(GGally)
library(ggcorrplot)
library(mgcv)

audi <- read_csv("data/audi.csv")
audi['brand'] = "Audi"

bmw <- read_csv("data/bmw.csv")
bmw['brand'] = "BMW"

ford <- read_csv("data/ford.csv")
ford['brand'] = "Ford"

hyundi <- read_csv("data/hyundi.csv")
hyundi['brand'] = "Hyundai"

merc <- read_csv("data/merc.csv")
merc['brand'] = "Mercedes"

skoda <- read_csv("data/skoda.csv")
skoda['brand'] = "Skoda"

toyota <- read_csv("data/toyota.csv")
toyota['brand'] = "Toyota"

vauxhall <- read_csv("data/vauxhall.csv")
vauxhall['brand'] = "Vauxhall"

vw <- read_csv("data/vw.csv")
vw['brand'] = "VW"

car_data <- rbind(audi, bmw, ford, hyundi, merc, skoda, toyota, vauxhall, vw)
car_data <- car_data %>%
  select('brand', everything())
car_data <- car_data %>% relocate('price', .after = last_col())

#replace year with age
car_data$age = 2020 - car_data$year
```

# Introduction
For this project, we used a dataset found on Kaggle.com provided by user Aditya [@Aditya]. It contains a collection of different used car listings obtained by searching through online marketplaces using a web scraper. The dataset is split into different files, one per car brand. The brands for which data is available are:

* Audi
* BMW
* Ford
* Hyundai
* Mercedes
* Skoda
* Toyota
* Vauxhall (= Opel in Great Britain)
* VW

Additionally, the data set contains files with premade subsets of above mentioned car brands, for example *cclass.csv*, which contains only listings for the Mercedes model C Class. We chose to only utilize the unfiltered datasets.

Apart from the car brand, there are a number of other attributes available for each data entry.

* car model
* year of first registration
* transmission type
* mileage
* fuel type
* tax
* miles per gallon of fuel
* engine size

as well as the target variable price.

# Business Understanding

## a. Scenario

A group of entrepreneurs in the used car business want to counteract the ongoing trend of people selling their cars to other private individuals directly without involving commercial reseller, which has become very easy given the availability of online market places for used goods. The idea is the following: Customers are offered a new web-based platform where they can enter the most important key facts about the car they would like to sell. The platform immediately returns a first estimate of the price the platform owners would pay for the car. This estimate should be based on a model created from the used car listing data available.

## b. Business Objectives

The business objectives is in short:

**What is the expected value of a used car based on the given data entries?**

Answering this question helps the platform in multiple ways.

* make it more convenient for customers to sell their used car by getting an accurate first estimate right after entering the data
* increase revenues by missing out on fewer chances to buy used cars (more cars resold via the platform instead of directly to other buyers)
* speed up final evaluation of car value by offering a good starting point
* base offers made to customers on true market values

## c. Business Success Criteria

The following criteria need to be met by the prediction:

* The estimate should lead to a conversion rate of more than 30%, meaning that at least 30% of the users that enter their car data on the website actually proceed to sell their car on the platform.

* The estimations should never lead to an effective loss for the company. Therefore, estimations that are too high need to be avoided.


## d. Data Mining Goals

In order to fulfill the business objective of determining an accurate price estimate, a regression problem needs to be solved. The input data consists of the 9 attributes mentioned above.

## e. Data Mining Success Criteria

Regarding the result of the estimation, one important success criterion is:

* The estimate needs to be within a range of the actual price +/- 15% for 95% of the estimations made.

This is important because estimates that are further off the actual price may lead to:

* People aborting the process when the estimate is much lower than their expectation
* People entering the negotiations with far inflated expectation, effectively reducing the changes of the platform owners to score a good deal


# Data Understanding
In the following section, a data description report containing data types, statistical properties, data quality aspects as well as a visual exploration of data properties is presented.

## a. Data Types
The attributes in the data set have the data types shown in **Table \@ref(tab:table-datatypes).**

```{r echo=FALSE}
Attribute <- c("model", "age", "year", "transmission", "mileage", "fuelType", "tax", "mpg", "engineSize", "price");
Type <- c("String, nominal", "Integer, interval", "Integer, ratio", "String, nominal", "Integer, ratio", "String, nominal", "Integer, ratio", "Float, ratio", "Float, ratio", "Integer, ratio")
data_types <- data.frame(Attribute, Type)
```

```{r table-datatypes, echo=FALSE}
data_types %>%
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Data Types of the source data")
```


## b. Statistical Properties

```{r}
options(width = 60)
summary(car_data)
```


## c. Data Quality aspects
Since the data is recorded from the internet there is the possibility of it containing invalid information or missing values.

To begin with, we check the data for missing values. However, in this speficic case, there are none.
```{r}
dim(car_data) ==
  dim(car_data[complete.cases(car_data),])
```

Next up, we check plausibility of some of the extreme cases of numerical values. To keep it short, we only included one exemplary output her and then summarize the findings.
```{r}
options(width = 60)
head(car_data[order(car_data$age),], 5)
# year 2060 is an error

head(car_data[order(-car_data$age),], 5)
# the oldest cars seem realistic
```
```{r echo=FALSE, include=FALSE}
#MILEAGE
head(car_data[order(car_data$mileage),], 10)
# year 2008 and only one mile does not seem realistic, especially given the price.

head(car_data[order(-car_data$mileage),], 10)
# other end looks good

# TAX
head(car_data[order(car_data$tax),], 10)
# tax seems realistic on the low end ("slow" cars = low tax)

head(car_data[order(-car_data$tax),], 10)
# tax seems realistic on the top end (fast cars = high tax)

# MPG
head(car_data[order(car_data$mpg),], 10)
head(car_data[order(-car_data$mpg),], 10)
# for MPG, both high and low and values do not seem realistic. There is definitely some need for cleaning here.

# ENGINE SIZE
head(car_data[order(car_data$engineSize),], 10)
head(car_data[order(-car_data$engineSize),], 10)
# on the upper end, everything looks good, but there are entries with engine size = 0 for petrol and diesel cars, which is not possible

# Price
head(car_data[order(car_data$price),], 10)
head(car_data[order(-car_data$price),], 10)
# pricing for the extreme values looks pretty good, however in the top 10, we were wondering if the high prices for e.g. the Mercedes A-Class (>130.000) are authentic.
```
Most of the extreme values in the dataset were realistic. Some entries contain questionable combinations of age and mileage, unrealistically high or low MPG values or "0" engine sizes. In those cases, some filtering should be done.

## d. Visual Exploration of data properties and hypotheses

In the following figures, boxplots in **Figure \@ref(fig:figure-boxplots)** illustrate the ranges of the numeric (ratio) variables.

```{r figure-boxplots, echo=FALSE, out.width='0.98\\textwidth', fig.env='figure*', fig.cap="Boxplots on the distribution of the numeric attributes"}
par(mfcol = c(1, 5), mai=c(0.3,0.3,0.3,0.1), cex = 0.7)
boxplot(car_data$engineSize, main="Engine Size")
boxplot(car_data$mileage, main="Mileage")
boxplot(car_data$price, main="Price")
boxplot(car_data$mpg, main="MPG")
boxplot(car_data$tax, main="Tax")
par(mfcol = c(1, 1))
```
There are a few things we can learn from these diagrams. For example, it is interesting to see car listings contained in the data set are mostly for rather new cars, with a mileage median of less than 25000 miles. Taking a look at **Figure \@ref(fig:car-age)**, this suspicion is confirmed. The vast majority of cars in the dataset is indeed less than five years old. There is `r length(car_data$age[car_data$age < 0])` entry where the cars year is seemingly bigger than 2020, that is 2060, which will have to be dealt with in later steps.

```{r car-age, echo=FALSE, out.width='0.98\\columnwidth', fig.cap="Histogram of car age."}
hist(car_data$age[car_data$age >= 0], xlim= c(0,30), main="Histogram of car age", xlab="Age (cleaned age < 0 entries)")
```

The correlation plot in **Figure \@ref(fig:correlationmatrix)** shows some pretty good correlation between ther predictor variables and the price, so we might be able to create a solid regression using the data available.

```{r, correlationmatrix, echo=FALSE, out.width='0.98\\columnwidth', fig.cap="Pairs of all numeric attributes"}
ggcorrplot(cor(data.matrix(car_data)))
```
From the view point of a human estimating the value of a used car, the most influential attributes should be age, mileage and brand/model as well as general condition, which is however not part of our dataset. Looking at the correlation matrix, we see that there is indeed a significant correlation between price and age as well as mileage. For model and brand, the correlation is much lower.

# Data Preparation report

## a. Potential for derived attributes

One adjustment that was already made right after importing the data was deriving the variable **age** from **year**. Our thoughts behind this decision were that as time progresses, a car's value usually decreases. Therefore, if we only use the year, we would have to discard all existing data sooner or later because it would be outdated. The age of the car at the time of the listing is a much more stable attribute in that regard. One assumption that we had to make here is that all the listings were collected in 2020, otherwise our age assignment would be wrong.
Other than that, we could not think of any variables where it would have made sense to derive new attributes.

## b. Potential for additional data sources

An attribute that we were especially missing in the dataset was **horse power**. Whilst we have different engine sizes in terms of stroke volume included, in practice we often see engines with the same size produce different amounts of maximal performance. Pricing is of course also higher for stronger engines (within a car model's options). Therefore, having additional horse power data in the set would have been desirable. Unfortunately, in many cases, it is impossible to add that information at a later point in time, since there is no reference to the original car listing included. In some cases, deriving the horse power from the other attributes might be possible. Usually, there will, however, be multiple choices, making it impossible to assign a value with 100% certainty.

Another very important aspect is the **condition** of the car. As previously mentioned, without knowing about the amount of damage that has already been done to a car, it is virtually impossible to judge its value. **Color** would be another interesting aspect since black or white cars are easier to sell than pink ones and therefore worth more. For both of these aspects, it is unfortunately again impossible to obtain values for the existing data set.

## Other Pre-Processing steps

In the following section, we will prepare the dataset for modeling but applying the needed corrections identified before.

#### Removing Outliers

In 2c) we identified several entries that cannot be valid data. Next, we remove those entries from our data frame.

First, there is one entry with a negative age.

```{r}
car_data <- car_data[car_data$age >= 0, ]
```

Next, we filter a few rows that seem unrealistic in terms of mileage and age.

```{r}
car_data <- car_data[!(car_data$mileage < 1000 &
                         car_data$age > 5), ]
```

The filtering becomes a little more interesting for miles per gallon. A quick Internet research produced the following results. In 2020, new cars with a combustion engine should be able to achieve around 25 miles per gallon on average. Top performers among hybrid cars can manage up to around 60 miles per hour. Everything significantly higher than that is currently not possible. On the lower end, we looked up some high performance sports cars. Even for the most powerful cars like the Bugatti Chiron or the Lamborghini Aventador, fuel economy scores were around 10 miles per gallon.

```{r}
nrow(car_data[car_data$mpg > 60, ])
```
Unfortunately, the car listings in the dataset do not seem to agree with this information. Around one third of the car listings show MPG values higher than 60. Upon further inspection, we came to the conclusion that the MPG values from the listings might correspond to manufacturer ideal values that are practically unobtainable in real world use. For petrol cars, the the mean of the MPG values is about 50, which is way higher than expected.

```{r}
summary(
  car_data[car_data$fuelType == "Petrol", ]$mpg)
```

For hybrid cars, the quartiles were higher, as expected.
```{r}
summary(
  car_data[car_data$fuelType == "Hybrid", ]$mpg)
```

Our strategy to clean the data here therefore was not to remove overall outliers, but outliers per fuel type.

```{r, echo=FALSE, include=FALSE}
old_length <- nrow(car_data)
```


```{r}
types <- distinct(
  car_data, car_data$fuelType)[, 1]$`car_data$fuelType`
for (type in types) {
  outliers <- boxplot(
    car_data[car_data$fuelType == type, ]$mpg,
    plot=FALSE)$out
  
  if (length(outliers) > 0) {
    car_data <- car_data[-which(car_data$mpg %in%
          outliers &car_data$fuelType == type),]
  }
}
```
This outlier removal procedure effectively filtered out `r old_length - nrow(car_data)` entries from the data frame.

Next up, data entries where the fuel type indicates a combustion engine but the engine size is 0 are removed.
```{r}
car_data <- car_data[!(car_data$engineSize == 0 
          & car_data$fuelType != "Electric"),]
```

Regarding the price outliers that seem unrealistic above, we could not find a satisfying solution. The data comes from online sources, and the prices are whatever the sellers them to. Therefore, in order to remove all of the outliers in terms of over- or undervaluation, an expert would have to look over every single entry to determine whether the price is justified. Therefore, we cannot even determine how many rows are affected and will simply assume that the prices are justified.

We did not remove any attributes. Binning did not seem to make sense, since we wanted to perform a regression where numerical precision is important.


c. Describe other pre-processing steps considered, specifying which ones were applied or not applied due to which reason. (e.g. data cleansing, transformations, binning, scaling, outlier removal, attribute removal, transcoding, ...) at a level of detail that ensures reproducibility of changes to the data. (Code may be supplied as supplement to the submission in case you produce your own code)


# Modeling

## a. Identify suitable data mining algorithms

The goal, as stated by the data mining goal, is to estimate the price for a car based on it inputed characteristics based on the training data containing nine attributes as well as the prediction lable. Therefore it is a supervised learning process for regression, the prediction of a continuous numerical value.
When choosing the a regression model it has to deliver sufficient results, while being efficient in computation.
While complex regression models might deliver higher accuracies, they easily become difficult to interpret and follow back decisions.
Generalized linear regression is the go to to regression model as it is fast to train and delivers good estimates and predictions. It's computational requirements depending on the data are managable.
As linear relationship of the attributes and the prediction value cannot be assumed, an alternative regression model is implemented and compared: the Generalized additive models (gam). It is based on the idea to combine generalized linear models and additive models.

## b. Hyper-parameters
Choosing a linear regression model leaves open the possibility to modify the formula to reproduce a linear relationship between the attributes and the predicted value. While doing it manually is very timeintensive and inefficient it can be implemented with the use of Generalized additive models (gam). This model allows to apply smoothing functions on the single parameters to improve prediction outcome. Effectively combining generalized linear models with additive models.

## c. Data Split in train / validation / test set

Dividin the data train, validation and test set. In the ratio:

* train: 70%
* validate: 15%
* test: 15%

To ensure reroducability a seed is set.

```{r}
set.seed(1)
assignment <- sample(1:3,
                     nrow(car_data),
                     prob = c(0.7,0.15,0.15),
                     replace = TRUE)

train_data <- car_data[assignment == 1,]
test_data <- car_data[assignment == 2,]
validate_data <- car_data[assignment == 3,]
```

Splitting the data in train, test and validation samples, caused failuers in the prediciton process, as some car models are very scarse or unique. Meaning the case happened of certain models appearing only in the testing or validation samples and therefore being unknown levels to the model. To resolve this issue, new levels (car models not present in the training sample) were removed from the testing and validation sample.
Further thought process on this matter in regards of usability in business are present in the deployment section.

```{r out.width='0.98\\columnwidth'}
# Analysing data on the carmodels
head(sort(table(car_data$model),decreasing = TRUE),5)
tail(sort(table(car_data$model),decreasing = TRUE),5)
# reveals that some carmodels are only present once in the datamodel

# Carmodels missing in the trainingdata
missing_fact_test <- setdiff(
  unique(test_data$model),
  unique(train_data$model))
missing_fact_validate <- setdiff(
  unique(validate_data$model),
  unique(train_data$model))

cleaned_test_data <- test_data[!test_data$model
    %in% missing_fact_test,]
cleaned_validate_data <- validate_data[!validate_data$model
    %in% missing_fact_validate,]
```

## d. Model Traning and Parameter Setting

As starting point for the regression model the linear regression model was taken without the addition of more elaborated parametetrisation. This already delivered a decent predicition accuracy.
Regarding the previously mentioned issue with the scarse car models, we tested the predicitionbehaviour with and without making use of the car model as an attribute. To explore what it has on the prediciton.
To measure the quality of a model the R-squared value is utilised. R-squared is describes the proportion of variation of the dependent value, that can be explained utilising the regression model. It gives a first performance value of the model before having to validate it utilising predictions. Furter performance comparisons are done using predictions with the validation set.

```{r, echo=TRUE, results='hide'}
# Example of prediction with car model
formula <- price~brand+mpg+mileage+
  year+transmission+fuelType+
  tax+engineSize+model

glm_model <- lm(formula,data = train_data)
glm_pred <- predict(glm_model,cleaned_test_data)
```

```{r, echo=FALSE, include=FALSE}
# without car model
formula <- price~brand+mpg+mileage+year+transmission+fuelType+tax+engineSize
# with car model
formula2 <- price~brand+mpg+mileage+year+transmission+fuelType+tax+engineSize+model

glm_model_noModels <- lm(formula,data = train_data)
glm_pred_noModels <- predict(glm_model_noModels,cleaned_test_data)
summary(glm_model_noModels)$r.squared

glm_model <- lm(formula2,data = train_data)
glm_pred <- predict(glm_model,cleaned_test_data)

rsquares <- c(summary(glm_model_noModels)$r.squared, summary(glm_model)$r.squared)
```

```{r, echo=FALSE}
data.frame(model = c("without car model","with car model"), R_square = rsquares) %>%
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Attribute selection impact")
```

As expected based on the correlation matrix, the car models do have impact on the prediction accuracy. This is further proven by the higher R-squared value. Therefore it will be used for further modelling.
While use of the linear regression model delivers good results, the linearity of the problem is only a hypothesis and in case of non-linearity an alternative model could deliver better results.
The use of the gam model allows for the computation of smoothening factors in the formula which can result in an improved prediction.

```{r, echo=FALSE, include=FALSE}
# Build the model
gam_model <- gam(price~ brand+s(mpg)+s(mileage)+s(year)+transmission+fuelType+tax+s(engineSize)+model, data = train_data)
# Make predictions
gam_pred <- gam_model %>% predict(cleaned_test_data)
```

e. Report suitable performance metrics supported, where possible, by figures/graphs showing the tuning process of the hyper parameter.


```{r, echo=FALSE, predictionHistograms, out.width='0.98\\columnwidth'}
par(mfcol = c(1, 2), cex = 0.7)
hist(cleaned_test_data$price-glm_pred,breaks = 200,
     main="GLM-Prediction errors")
hist(cleaned_test_data$price-gam_pred,breaks = 200,
     main="GAM-Prediction errors")
par(mfcol = c(1, 1))
```

```{r, echo=FALSE, predictionBoxplots, out.width='0.98\\columnwidth'}
par(mfcol = c(1, 2), cex = 0.7)
glm_means<-((cleaned_test_data$price - glm_pred)/
              cleaned_test_data$price)
boxplot(glm_means * 100,
        main="GLM-Predicion errors in %", outline=FALSE)
gam_means <- ((cleaned_test_data$price - gam_pred)/
                cleaned_test_data$price)
boxplot(gam_means,
        main="GAM-Prediction errors in %", outline=FALSE)
par(mfcol = c(1, 1))
```

```{r}
summary(abs((cleaned_test_data$price -
    gam_pred)/cleaned_test_data$price))
```


```{r, glmscatter, echo=FALSE, out.width='0.98\\columnwidth', fig.cap="Scatter plot of GLM predictions vs true prices"}
results <- data.frame(true = cleaned_test_data$price, gam = gam_pred, glm = glm_pred)
ggplot(results,aes(x=true,y=glm)) + geom_point(alpha = 0.2) + xlab("actual price") + ylab("predicted price")
```

```{r, gamscatter, echo=FALSE, out.width='0.98\\columnwidth', fig.cap="Scatter plot of GAM predictions vs true prices"}
ggplot(results,aes(x=true,y=gam)) + geom_point(alpha = 0.2) + xlab("actual price") + ylab("predicted price")
```

## Tuning process

Over the last step the regression model was optimised and tested by modifying the training attributes, the model itself and the parameters. Summary of the continuous optimisations are summarised in the table below:
```{r, echo=FALSE}
rsquares <- c(summary(glm_model_noModels)$r.squared, summary(glm_model)$r.squared,summary(gam_model)$r.sq)
data.frame(model = c("GLM (w/o car model)", "GLM ", "GAM"), R_square = rsquares ) %>%
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Attribute selection impact")
```


# Evaluation

```{r, echo=FALSE, include=FALSE}
# Evaluate models
gam_pred_val <- gam_model %>%
  predict(cleaned_validate_data)

mean(abs((cleaned_validate_data$price - gam_pred_val)/cleaned_validate_data$price))
```

As final evaluation of the model the validation set is used.
Since the validation set was not utilized until now, neither the model or its parameters are optimized for it. It can be seen as a simulation of new data being applied to it. The mean relative error is `r mean(abs((cleaned_validate_data$price - gam_pred_val)/cleaned_validate_data$price))` which is above the data mining success criterion.

The boxplot in **Figure \@ref(fig:evaluationBoxplot)** shows the errors for the validation set with GAM predictions.

```{r, evaluationBoxplot, echo=FALSE, out.width='0.98\\columnwidth', fig.cap="Pairs of all numeric attributes"}
boxplot(cleaned_validate_data$price - gam_pred_val)
```

The boxplot data in numbers:
```{r echo=FALSE}
summary(abs((cleaned_validate_data$price -
  gam_pred_val)/cleaned_validate_data$price))
```

## b. Retraining with train and test data

To further evaluate the model it is now trained utilizing all except the validation data set.
```{r, echo=FALSE, include=FALSE}
gam_model_eval <- gam(price~ brand+s(mpg)+s(mileage)+s(year)+transmission+fuelType+tax+s(engineSize)+model, data = rbind(train_data,cleaned_test_data))
gam_pred_eval_2 <- gam_model_eval %>% predict(cleaned_validate_data)
```
The mean error (`r mean(abs((cleaned_validate_data$price - gam_pred_eval_2)/cleaned_validate_data$price))`) does not change significantly, which points to good stability of the model. Bringing confidence in its usability with new data collected in future years.

## c. + d. Identify and document expected performance from other sources

In a case study found on towardsdatascience.com, a similar prediction is made using some other algorithms. The used dataset has more attributes as well as more rows compared to ours. There, they only evaluate the performance in terms of absolute errors. In their case, the best performing algorithm was Random Forest with a mean absolute error of 2047 dollars. [@Gokce] Our model produced a mean absolute error of `r mean(abs(cleaned_validate_data$price - gam_pred_eval_2))` (GAM) GBP, which is comparable.

## e. Compare the performance obtained with the Data Mining success criteria defined in the business understanding phase.
Reflecting on the initially stated success criteria:

* The estimate needs to be within a range of the actual price +/- 15% for 95% of the estimations made.

```{r}
relative_error <- (cleaned_validate_data$price -
  gam_pred_eval_2)/cleaned_validate_data$price
relative_error_abs <- abs(relative_error)

error_of_95_abs <- sort(relative_error_abs)[
  floor(nrow(relative_error_abs)*0.95)]

mean_error_of_95_abs <- mean(sort(relative_error_abs)[
  sort(relative_error_abs)<error_of_95_abs])
ratio_lower_15 <-
  nrow(relative_error_abs[relative_error_abs <
    0.15])/nrow(relative_error_abs)
```

Looking back the initial set goal, it was not possible to achieve the set goal. For 95% of the data a max error **`r ratio_lower_15`** can be ensured, while the absolut mean error for 95% is **`r round(mean_error_of_95_abs,3)`**, however this can be positively or negatively which means it can either benefit the customer or the business.

# Deployment

## a. Deployment Recommendations

Since we did not quite manage to reach our set data mining success criteria, we would definitely recommend placing a disclaimer next to the application stating that the estimates are without any warranty. But jokes aside, an easy way of improving the predictions is by filtering out obviously wrong predictions like negative prices, which could be done by a module applied after the model. In concrete terms, the web page could return an error message or redirect to a manual evaluation if the model returns a value smaller than zero. 

## b. Ethical and impact assessment

The only problem that could be related to an ethical discussion we could think of was the potential of false overestimation which would leave concerned users very disappointed. Especially for people in a difficult finiancial situation, this behaviour could cause additional stress. This problem concerns also the employees of the car trading company who have to deal with informing the customers about the wrong evaluation of their car. For those employees, this can also become quite frustrating if it happens often.

## c. Aspects to be monitored

Since the model is trained on certain car brands and models only, it is unable to predict the price of those cars not found in the dataset. We therefore recommend logging all requests to the service in order to determine which car models that are not included in the model are frequently queried. That way, the model can incrementally completed in the future, starting with the most relevant car models.
Another very important aspect is the comparision of model prediction and actual sales price. This helps quickly recognize a deterioration in prediction accuracy and then retrain the model.

## Reproducibility

One decision that we made might be a bit random, and that is the decision to remove all cars with a very low mileage over a certain age. Inversely, decisions like removing outliers based on fuel type AND mpg definitely make sense.


# Summary of findings

To sum it all up, we created a decent prediction model that is able to produce rather accurate estimates. However, we would not recommend using it in a production scenario for several reasons. First of all, there is a wide range of attributes that could be valuable for the model to know about that simply were not included in the dataset. An actual users, however, would of course know about the values of these attributes, for example color. This means that the accuracy of the predictions could potentially improve a lot. In order to achieve that, one would however have to collect an entirely new data set, but we think that the effort would be worth it.

Regarding the exercise itself, we quite liked being confronted with a realistic scenario and trying to come up with a solution for it. However, what we think would have been very useful is some kind of example solution. We are new to data science, so it was quite hard to get a feeling of what was expected. Overall, a good exercise where we learned something.
